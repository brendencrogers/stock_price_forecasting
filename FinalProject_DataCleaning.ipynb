{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2N4NgLHHeEdH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "from datetime import datetime\n",
        "import time\n",
        "\n",
        "apikey = \"rG3tQa9lws5UNKCLP1poUjP65xVSe_Wl\"\n",
        "alpha_key = \"TGVHMDFHS5MWFDXF\"\n",
        "sec_key = 'e0a0986222f34fbdcd03fd20258d687bcc2da4fa3311ca77595a855750728bea'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "polygon = requests.get(\"https://api.polygon.io/v2/aggs/ticker/SPY/range/1/day/2000-07-01/2022-03-01?limit=5000&apiKey=%s\" % (apikey))"
      ],
      "metadata": {
        "id": "fXfGU964e60Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inflation = requests.get('https://www.alphavantage.co/query?function=INFLATION_EXPECTATION&apikey=%s' % alpha_key)\n",
        "treasury_yields = requests.get(\"https://www.alphavantage.co/query?function=TREASURY_YIELD&interval=daily&apikey=%s\" % alpha_key)\n",
        "unemployment = requests.get(\"https://www.alphavantage.co/query?function=UNEMPLOYMENT&apikey=%s\" % alpha_key)"
      ],
      "metadata": {
        "id": "iwgGge_4tKPR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "locs = requests.get(\"https://api.sec-api.io/mapping/exchange/BATS?token=%s\" % sec_key)"
      ],
      "metadata": {
        "id": "sxow69CWANmc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "daily_data = pd.json_normalize(polygon.json(), [\"results\"])\n",
        "daily_data[\"t\"] = pd.to_datetime(daily_data[\"t\"].apply(lambda x: datetime.fromtimestamp(x / 1000).strftime(\"%Y-%m-%d\")))"
      ],
      "metadata": {
        "id": "hLkstmilibDY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inflation_data = pd.json_normalize(inflation.json(), [\"data\"])\n",
        "yields_data = pd.json_normalize(treasury_yields.json(), [\"data\"])\n",
        "employment_data = pd.json_normalize(unemployment.json(), [\"data\"])\n",
        "location_data = pd.json_normalize(locs.json())\n",
        "inflation_data[\"date\"] = pd.to_datetime(inflation_data[\"date\"])\n",
        "yields_data[\"date\"] = pd.to_datetime(yields_data[\"date\"])\n",
        "employment_data[\"date\"] = pd.to_datetime(employment_data[\"date\"])"
      ],
      "metadata": {
        "id": "Yl67wtsL9VM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dates_vals_inf = []\n",
        "dates_vals_emp = []\n",
        "\n",
        "for i in range(len(inflation_data[inflation_data[\"date\"] >= datetime(2020, 3, 1)]) - 1):\n",
        "  time_range = pd.date_range(inflation_data.loc[i+1].date, inflation_data.loc[i].date)\n",
        "  dates_vals_inf.append(pd.Series(len(time_range) * [inflation_data.loc[i].value], index=time_range))\n",
        "\n",
        "for i in range(len(employment_data[employment_data[\"date\"] >= datetime(2020, 3, 1)]) - 1):\n",
        "  time_range = pd.date_range(employment_data.loc[i+1].date, employment_data.loc[i].date)\n",
        "  dates_vals_emp.append(pd.Series(len(time_range) * [employment_data.loc[i].value], index=time_range))"
      ],
      "metadata": {
        "id": "U3gFMAy4JvLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inflation_series = dates_vals_inf[0]\n",
        "employment_series = dates_vals_emp[0]\n",
        "\n",
        "for series in dates_vals_inf[1:]:\n",
        "  inflation_series = pd.concat([inflation_series, series])\n",
        "\n",
        "for series in dates_vals_emp[1:]:\n",
        "  employment_series = pd.concat([employment_series, series])\n",
        "\n",
        "inf_df = inflation_series.sort_index(ascending=True).to_frame(name=\"monthly_inflation_exp\")\n",
        "emp_df = employment_series.sort_index(ascending=True).to_frame(name=\"employment_rate\")\n",
        "inf_df = inf_df.reset_index().rename(columns={\"index\": \"date\"})\n",
        "emp_df = emp_df.reset_index().rename(columns={\"index\": \"date\"})"
      ],
      "metadata": {
        "id": "AFHCLGsvOR32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all = daily_data.copy()\n",
        "all[\"t\"] = pd.to_datetime(all[\"t\"])\n",
        "all = all.merge(yields_data[yields_data[\"date\"] >= datetime(2020, 3, 1)], how=\"left\", left_on=\"t\", right_on=\"date\").drop(\"date\", axis=1).rename(columns={\"value\": \"10Y yield\"})\n",
        "all = all.merge(inf_df, how=\"left\", left_on=\"t\", right_on=\"date\").drop(\"date\", axis=1)\n",
        "stock_df = all.merge(emp_df, how=\"left\", left_on=\"t\", right_on='date').drop(\"date\", axis=1)\n",
        "stock_df[\"monthly_inflation_exp\"] = stock_df[\"monthly_inflation_exp\"].replace(np.nan, 5)\n",
        "stock_df.employment_rate = stock_df[\"employment_rate\"].replace(np.nan, 3.6).astype(float)"
      ],
      "metadata": {
        "id": "9bV1gknFD3h5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stock_df[\"daily return\"] = stock_df[\"c\"].pct_change()\n",
        "stock_df[\"daily return\"] = stock_df[\"daily return\"].replace(np.nan, 0)\n",
        "stock_df[\"10Y yield\"] = stock_df[\"10Y yield\"].replace(\".\", np.nan)\n",
        "stock_df = stock_df.dropna()\n",
        "dates = stock_df.set_index(\"t\").index\n",
        "stock_df[\"time\"] = dates.year + (30 * (dates.month - 1) + dates.day) / 365"
      ],
      "metadata": {
        "id": "YkbLal5JR6CI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98341a22-7ea9-44d7-a308-a1408ebc2da8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stock_df.to_csv(\"stock_df.csv\")"
      ],
      "metadata": {
        "id": "PER-ZXz5U4lg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "companies = pd.json_normalize(locs.json())\n",
        "prices = []\n",
        "locations = companies[companies[\"location\"] != \"\"]\n",
        "\n",
        "for tick in locations[\"ticker\"][:200]:\n",
        "  respose = requests.get(\"https://api.polygon.io/v2/aggs/ticker/%s/prev?limit=5000&apiKey=%s\" % (tick, apikey))\n",
        "  try:\n",
        "    price = pd.json_normalize(respose.json(), [\"results\"])[\"c\"][0]\n",
        "    prices.append(price)\n",
        "  except KeyError:\n",
        "    prices.append(np.nan)\n",
        "  time.sleep(12)\n"
      ],
      "metadata": {
        "id": "ce61SqBgfRiy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "locations = locations.iloc[:200]\n",
        "locations[\"price\"] = prices\n",
        "locations.to_csv(\"locations.csv\")"
      ],
      "metadata": {
        "id": "_zwHasx_BRkG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ticker_lst = [\"AAPL\", \"MSFT\", \"NVDA\", \"HD\", \"COST\", \"T\", \"TSLA\", \"F\", \"KO\", \"NKE\", \"JPM\", \"XOM\", \"GS\", \"JNJ\", \"CNC\", \"ABBV\", \"DOW\", \"GE\", \"BBY\", \"TWTR\", \"D\", \"VZ\", \"AMAT\", \"BA\", \"DAL\", \"PARA\", \"EXPE\", \"DIS\", \"BYND\"]\n",
        "metrics = []\n",
        "\n",
        "df_metrics = pd.json_normalize(requests.get(\"https://www.alphavantage.co/query?function=OVERVIEW&symbol=AAPL&apikey=%s\" % alpha_key).json())\n",
        "\n",
        "for tick in ticker_lst[1:]:\n",
        "  response = requests.get(\"https://www.alphavantage.co/query?function=OVERVIEW&symbol=%s&apikey=%s\" % (tick, alpha_key))\n",
        "  df = pd.json_normalize(response.json())\n",
        "  df_metrics = pd.concat([df_metrics, df])\n",
        "  time.sleep(12)"
      ],
      "metadata": {
        "id": "ii5gnrHNQxix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_metrics.to_csv(\"metrics.csv\")"
      ],
      "metadata": {
        "id": "zzkgVEYyTjl5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tsla = pd.read_csv(\"TSLA_prices.csv\", parse_dates=True)\n",
        "att = pd.read_csv(\"T_prices.csv\", parse_dates=True)\n",
        "ko = pd.read_csv(\"KO_prices.csv\", parse_dates=True)"
      ],
      "metadata": {
        "id": "pRvPemydHw_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tsla[\"t\"] = pd.to_datetime(tsla[\"Date\"]) \n",
        "att[\"t\"] = pd.to_datetime(att[\"Date\"]) \n",
        "ko[\"t\"] = pd.to_datetime(ko[\"Date\"])\n",
        "\n",
        "dates = tsla.set_index(\"t\").index\n",
        "tsla[\"time\"] = dates.year + (30 * (dates.month - 1) + dates.day) / 365\n",
        "dates = att.set_index(\"t\").index\n",
        "att[\"time\"] = dates.year + (30 * (dates.month - 1) + dates.day) / 365\n",
        "dates = ko.set_index(\"t\").index\n",
        "ko[\"time\"] = dates.year + (30 * (dates.month - 1) + dates.day) / 365"
      ],
      "metadata": {
        "id": "3t6wM50lH17d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tsla[\"daily return\"] = tsla[\"% Return\"].replace(np.nan, 0)\n",
        "att[\"daily return\"] = att[\"% Return\"].replace(np.nan, 0)\n",
        "ko[\"daily return\"] = ko[\"% Return\"].replace(np.nan, 0)"
      ],
      "metadata": {
        "id": "QFdnADXSIClk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tsla[\"Price\"] = tsla[\"Price\"].replace(\",\", \"\")\n",
        "att[\"Price\"] = att[\"Price\"].replace(\",\", \"\")\n",
        "ko[\"Price\"] = ko[\"Price\"].replace(\",\", \"\")"
      ],
      "metadata": {
        "id": "bN6P7eGeKuZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tsla.to_csv(\"tsla.csv\")\n",
        "att.to_csv(\"att.csv\")\n",
        "ko.to_csv(\"ko.csv\")"
      ],
      "metadata": {
        "id": "xS_M_x2kJArV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}